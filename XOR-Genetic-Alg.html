<p id="test"></p>
<script>

//Stores all nn's
var neuralNetworks = [];
var outputs = [];
var costs = [];

var maxNumOfNNs = 0;

var sumCost = 0;
var meanCost;

var maxMutation = 0.0001;
var squishingFunction = "tanh";
var maxRandomForWeights = 1;
var maxRandomForBiases = 1;

//Sigmoid function
//https://www.justgivemeanexample.com/example/create-a-sigmoid-function-in-javascript
function squish(input, method) {
	if(method == "sigmoid"){
		return 1 / (1 + Math.exp(-input));
    } else if (method == "tanh"){
    	return Math.tanh(input)
    }
}

function getRandomFloat(min, max) {
  return Math.random() * (max - min) + min;
}



function init(numOfnns) {
	maxNumOfNNs = numOfnns;
	for (var i = 0; i < numOfnns; i++) {
		neuralNetworks.push({
			//2 inputs
			//4 weights
			weights1: [getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights)],
			//2 biases
			biases: [getRandomFloat(-maxRandomForBiases, maxRandomForBiases), getRandomFloat(-maxRandomForBiases, maxRandomForBiases)],
			//4 weights
			weights2: [getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights), getRandomFloat(-maxRandomForWeights, maxRandomForWeights)],
            //1 bias
            bias2: getRandomFloat(-maxRandomForBiases, maxRandomForBiases)

			//1 output
		});
	}
}


function calcOutput(input1, input2, index) {
	//Calculates the input of the two hidden neurons
	//While this could be done all at once, I find it's easier to understand this way.
	var hn1 = squish((input1 * neuralNetworks[index].weights1[0]) + (input2 * neuralNetworks[index].weights1[2]) + neuralNetworks[index].biases[0], squishingFunction);

	var hn2 = squish( (input1 * neuralNetworks[index].weights1[1]) + (input2 * neuralNetworks[index].weights1[3]) + neuralNetworks[index].biases[1], squishingFunction);

	var output = squish(hn1 * neuralNetworks[index].weights2[0] + hn2 * neuralNetworks[index].weights2[1] , squishingFunction);

	return output;

}

//Initializes the amount of neural networks requested by the user with random weights and biases
init(2500);


function cycle(){
var sumCost = 0;
var outputs = [];
var costs = [];
var meanCost;
	//Calculate all the outputs for all the NN's and all possible inputs, and store it in the outputs array.
	for (var i = 0; i < neuralNetworks.length; i++) {
		outputs.push([calcOutput(0, 0, i), calcOutput(0, 1, i), calcOutput(1, 1, i), calcOutput(1, 0, i)]);
	}

	//After that's done, calculate the cost using the mean squared error.
	//Again, this could be done in one step, and should be for efficiency's sake, but to make it easier to understand I'm seperating the steps
	for (var i = 0; i < outputs.length; i++) {
		//Calculates the difference between the predicted and actual answer for XOR of 1 and 1 and squares it
		//Same for all of the others

		var xor00Difference = Math.pow(outputs[i][0] - 0, 2);
		var xor01Difference = Math.pow(outputs[i][1] - 1, 2);
		var xor11Difference = Math.pow(outputs[i][2] - 0, 2);
		var xor10Difference = Math.pow(outputs[i][3] - 1, 2);

		//Outputs the mean of the differences to the costs array
        var output =  (xor00Difference + xor01Difference + xor11Difference + xor10Difference)/4
		costs.push(output);

	}

	//Now there are multiple ways that we could find out which algorithms did the best, but since I'm not smart enough to do it another way, we're going to find the mean of all of the algorithms' costs, and which ever ones are lower than the mean get to survive

	//First, we've gotta find the mean

	//Find the sum of all of the costs
	for (var i = 0; i < costs.length; i++) {
		sumCost += costs[i];
	}


	//And divide it by the number of costs
	meanCost = (sumCost/costs.length);

	//Now we check every individual agorithm's cost, and if the cost is higher than the average (which means it performed worse), it dies. 
	//Gruesome ik
	//Do this repeatedly, until the number of neural networks is below half of the original amount and there's an even number
	//Again, this is a really lazy approach to doing this, but it should work for the time being

	var badIndexes = [];

	/**While this is a pretty complex and computationally expensive method, 
	it's a simple one to produce. If i just removed all of the bad indexes with array.splice(), it would always stop after removing 50.
	**/

//Sort the arrays in descending order from least to greatest, and then delete the bottom half.

   var len = costs.length;
   for (var i = len-1; i>=0; i--){
     for(var j = 1; j<=i; j++){
       if(costs[j-1]>costs[j]){
           var temp = costs[j-1];
           var temp2 = neuralNetworks[j-1];
           
           costs[j-1] = costs[j];
           costs[j] = temp;
           
           neuralNetworks[j-1] = neuralNetworks[j];
           neuralNetworks[j] = temp2;
        }
     }
   }
   
   neuralNetworks.splice(Math.floor(neuralNetworks.length/2) )
   costs.splice(Math.floor(costs.length/2) )
   
   




	//First, we make sure that nobody the number of nn's has gotten lower
	if (maxNumOfNNs - neuralNetworks.length > 0) {
		for (var i = 0; i < (maxNumOfNNs - neuralNetworks.length); i++) {
var nn1 = neuralNetworks[Math.floor(Math.random() * neuralNetworks.length)];
			var nn2 = neuralNetworks[Math.floor(Math.random() * neuralNetworks.length)];
			neuralNetworks.push({
				weights1: [ (Math.random()) > 0.5 ? nn1.weights1[0] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights1[0]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights1[1] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights1[1]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights1[2] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights1[2]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights1[3] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights1[3]+ getRandomFloat(-maxMutation, maxMutation) ],
                
				biases: [ (Math.random()) > 0.5 ? nn1.biases[0] + getRandomFloat(-maxMutation, maxMutation) : nn2.biases[0]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.biases[1] + getRandomFloat(-maxMutation, maxMutation) : nn2.biases[1]+ getRandomFloat(-maxMutation, maxMutation) ],
                
				weights2:[ (Math.random()) > 0.5 ? nn1.weights2[0] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights2[0]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights2[1] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights2[1]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights2[2] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights2[2]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.weights2[3] + getRandomFloat(-maxMutation, maxMutation) : nn2.weights2[3]+ getRandomFloat(-maxMutation, maxMutation) ],
                
                bias2: [ (Math.random()) > 0.5 ? nn1.bias2[0] + getRandomFloat(-maxMutation, maxMutation) : nn2.bias2[0]+ getRandomFloat(-maxMutation, maxMutation), (Math.random()) > 0.5 ? nn1.bias2[1] + getRandomFloat(-maxMutation, maxMutation) : nn2.bias2[1] + getRandomFloat(-maxMutation, maxMutation) ]
			});
            
		}
        
        
        
          document.getElementById('test').innerHTML = meanCost + "<p>" + neuralNetworks.length + "</p>" + "<p>" + costs[0]+"</p>" + calcOutput(1, 0, 0) + "<p>" ;          
	} else {
      document.getElementById('test').innerHTML = "DONE!";
      document.getElementById('test').innerHTML += "<p> " + calcOutput(1, 0, 0) + "</p>" ;

    }
    
    
    


requestAnimationFrame(cycle)
}     

cycle();




</script>
